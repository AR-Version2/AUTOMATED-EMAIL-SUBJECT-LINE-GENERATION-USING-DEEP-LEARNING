# -*- coding: utf-8 -*-
"""5c. manual rating doc to csv.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HM7sCJSKQzGklOaVFYgYFEgJEHM8Qbch
"""

import pandas as pd

def fill_rater_values(input_csv_file, output_excel_file="rated_output.xlsx"):
    """
    Reads a CSV file, simulates Rater 1 and Rater 2 evaluations based on
    Enron-specific criteria, and writes the results to an Excel file.

    Args:
        input_csv_file (str): Path to the input CSV file.
        output_excel_file (str, optional): Name of the output Excel file.
                                         Defaults to "rated_output.xlsx".
    """
    try:
        # Read the input CSV file into a Pandas DataFrame
        df = pd.read_csv(input_csv_file)

        # Function to simulate Rater 1's evaluations (Average Enron Employee)
        def rater1_evaluation(row):
            """
            Simulates an "Average Enron Employee" rating the email subject line.
            """
            relevance = 1  # Default value (lowest possible)
            conciseness = 1  # Default value (lowest possible)
            fluency = 3  # Default value

            subject_lower = row["SubjectToRate"].lower()
            email_lower = row["EmailBody"].lower()

            # Time Sensitivity & Importance: High Relevance for Urgency
            if "urgent" in subject_lower or "important" in subject_lower or "reminder" in subject_lower:
                relevance = 4
            elif any(phrase in email_lower for phrase in ["meeting", "schedule", "report", "analysis", "deadline"]):
                relevance = 3
            elif any(phrase in subject_lower for phrase in ["update", "new", "revised"]):
                relevance = 2
            else:
                relevance = 1

            # Conciseness:  Short & Familiar Terms are Key
            word_count = len(subject_lower.split())
            if word_count <= 3:
                conciseness = 4  # Excellent
            elif word_count <= 7:
                conciseness = 3
            elif word_count <= 10:
                conciseness = 2
            else:
                conciseness = 1  # Too lengthy

            # Fluency: Clear, Non-Confusing Language
            if any(term in subject_lower for term in ["isda", "pro forma", "dpr", "eol", "roce"]):  # Enron-specific jargon
                fluency = 1  # Penalize Jargon
            elif len(subject_lower) > 50:  # Long and complex subjects
                fluency = 2
            else:
                fluency = 3  # Generally good

            return relevance, conciseness, fluency

        # Function to simulate Rater 2's evaluations (Detail-Oriented Enron Professional)
        def rater2_evaluation(row):
            """
            Simulates a "Detail-Oriented Enron Professional" rating the email
            subject line based on usefulness for long-term management.
            """
            relevance = 1  # Default
            conciseness = 1  # Default
            fluency = 3  # Default

            subject_lower = row["SubjectToRate"].lower()
            email_lower = row["EmailBody"].lower()

            # Relevance: Keywords are Vital for Searching and Filing
            if any(keyword in subject_lower for keyword in ["report", "analysis", "forecast", "budget", "isda", "contract", "agreement"]):
                relevance = 4
            elif any(phrase in email_lower for phrase in ["legal", "compliance", "regulatory", "financial"]):
                relevance = 3
            elif any(phrase in subject_lower for phrase in ["q1", "q2", "q3", "q4", "2000", "2001", "2002"]):  # Time based phrases
                relevance = 2
            else:
                relevance = 1

            # Conciseness: Key Info, Suitable for Professional Communication
            length = len(subject_lower)
            if 15 <= length <= 40:
                conciseness = 4  # Ideal
            elif 10 <= length < 15 or 40 < length <= 60:
                conciseness = 3
            else:
                conciseness = 1  # Too Short or Too Long

            # Fluency: Appropriate Tone and Language for Enron Culture
            if any(word in subject_lower for word in ["congratulations", "thanks", "welcome", "update", "reminder"]):
                fluency = 4  # Professional and Courteous
            elif "urgent" in subject_lower or "action required" in subject_lower:
                fluency = 3  # Slights less formal, but acceptable
            elif any(word in subject_lower for word in ["lol", "asap", "fyi"]):
                fluency = 1  # Too Informal
            else:
                fluency = 2 #Generally good, Neutral

            return relevance, conciseness, fluency

        # Apply the evaluation functions to each row
        df[["Rater1_Relevance", "Rater1_Conciseness", "Rater1_Fluency"]] = df.apply(
            lambda row: rater1_evaluation(row), axis=1, result_type="expand"
        )

        df[["Rater2_Relevance", "Rater2_Conciseness", "Rater2_Fluency"]] = df.apply(
            lambda row: rater2_evaluation(row), axis=1, result_type="expand"
        )

        # Write the updated DataFrame to an Excel file
        df.to_excel(output_excel_file, index=False)

        print(f"Successfully created {output_excel_file}")

    except FileNotFoundError:
        print(f"Error: {input_csv_file} not found.")
    except Exception as e:
        print(f"An error occurred: {e}")


# Specify the input and output file names
input_file = "human_evaluation_sheet_input_20250417_023722.csv"  # Replace with your actual file name
output_file = "human_evaluation_sheet_rated.xlsx"

# Run the function to fill the ratings and create the Excel file
fill_rater_values(input_file, output_file)